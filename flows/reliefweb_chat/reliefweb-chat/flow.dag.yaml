$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
    default: []
  question:
    type: string
    is_chat_input: true
    default: what's the latest news from sudan
outputs:
  output:
    type: string
    reference: ${process_output.output.text_output}
    is_chat_output: true
  full_output:
    type: string
    reference: ${process_output.output}
nodes:
- name: extract_entities
  type: llm
  source:
    type: code
    path: extract_entities.jinja2
  inputs:
    deployment_name: gpt-35-turbo
    temperature: 0
    text: ${inputs.question}
  connection: azure_openai
  api: chat
  activate:
    when: ${content_safety.output.suggested_action}
    is: Accept
- name: create_rweb_query
  type: llm
  source:
    type: code
    path: create_rweb_query.jinja2
  inputs:
    deployment_name: gpt-35-turbo
    temperature: 0
    question: ${extract_entities.output}
  connection: azure_openai
  api: chat
- name: get_rweb_results
  type: python
  source:
    type: code
    path: get_rweb_results.py
  inputs:
    query: ${create_rweb_query.output}
- name: summarize
  type: llm
  source:
    type: code
    path: summarize.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k
    temperature: 0
    text: ${get_rweb_results.output}
  connection: azure_openai
  api: chat
- name: process_output
  type: python
  source:
    type: code
    path: process_output.py
  inputs:
    refs: ${extract_references.output}
    user_question: ${inputs.question}
    query_entities: ${extract_entities.output}
    rweb_results: ${get_rweb_results.output}
    llm_summary_result: ${summarize.output}
    llm_question_result: ${answer_question.output}
    rweb_query: ${create_rweb_query.output}
    content_safety_result: ${content_safety.output.suggested_action}
- name: extract_references
  type: python
  source:
    type: code
    path: extract_references.py
  inputs:
    results: ${get_rweb_results.output}
- name: answer_question
  type: llm
  source:
    type: code
    path: answer_question.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k
    temperature: 0
    response_format:
      type: json_object
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
    reliefweb_data: ${get_rweb_results.output}
  connection: azure_openai
  api: chat
- name: content_safety
  type: python
  source:
    type: package
    tool: promptflow.tools.azure_content_safety.analyze_text
  inputs:
    connection: azure_content_safety_connection
    text: ${inputs.question}
